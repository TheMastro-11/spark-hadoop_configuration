Spark Command: /usr/lib/jvm/java-8-openjdk-amd64/bin/java -cp /home/ubuntu/spark/conf/:/home/ubuntu/spark/jars/*:/home/ubuntu/hadoop/conf -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 //172.31.28.105:7077
========================================
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
24/02/27 18:11:33 INFO Worker: Started daemon with process name: 4417@ip-172-31-28-105
24/02/27 18:11:33 INFO SignalUtils: Registering signal handler for TERM
24/02/27 18:11:33 INFO SignalUtils: Registering signal handler for HUP
24/02/27 18:11:33 INFO SignalUtils: Registering signal handler for INT
24/02/27 18:11:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/02/27 18:11:34 INFO SecurityManager: Changing view acls to: ubuntu
24/02/27 18:11:34 INFO SecurityManager: Changing modify acls to: ubuntu
24/02/27 18:11:34 INFO SecurityManager: Changing view acls groups to: 
24/02/27 18:11:34 INFO SecurityManager: Changing modify acls groups to: 
24/02/27 18:11:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ubuntu; groups with view permissions: EMPTY; users with modify permissions: ubuntu; groups with modify permissions: EMPTY
24/02/27 18:11:34 INFO Utils: Successfully started service 'sparkWorker' on port 40467.
24/02/27 18:11:34 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[main,5,main]
org.apache.spark.SparkException: Invalid master URL: spark:////172.31.28.105:7077
	at org.apache.spark.util.Utils$.extractHostPortFromSparkUrl(Utils.scala:2401)
	at org.apache.spark.rpc.RpcAddress$.fromSparkURL(RpcAddress.scala:54)
	at org.apache.spark.deploy.worker.Worker$.$anonfun$startRpcEnvAndEndpoint$3(Worker.scala:966)
	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at scala.collection.TraversableLike.map(TraversableLike.scala:286)
	at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)
	at org.apache.spark.deploy.worker.Worker$.startRpcEnvAndEndpoint(Worker.scala:966)
	at org.apache.spark.deploy.worker.Worker$.main(Worker.scala:935)
	at org.apache.spark.deploy.worker.Worker.main(Worker.scala)
24/02/27 18:11:34 INFO ShutdownHookManager: Shutdown hook called
